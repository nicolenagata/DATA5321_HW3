{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15e3675e-e467-415d-bc5c-1c870f1d39ff",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b275dff2-03f3-41ab-8f7c-35575e22f727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amecro', 'amerob', 'bewwre', 'bkcchi', 'daejun', 'houfin', 'houspa', 'norfli', 'rewbla', 'sonspa', 'spotow', 'whcspa']\n"
     ]
    }
   ],
   "source": [
    "### Import data\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Specify file path\n",
    "file_path = r\"C:\\Users\\nnaga\\Downloads\\bird_spectrograms.hdf5\"\n",
    "\n",
    "# Open the file\n",
    "f = h5py.File(file_path, 'r')\n",
    "\n",
    "# Print keys (12 species)\n",
    "print(list(f.keys()))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac013349-2c74-4374-9d83-14baf971f093",
   "metadata": {},
   "source": [
    "### Binary Classification: Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd663662-b940-4ef9-9a22-c2b455df0045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 128, 517) (40, 1)\n",
      "(20, 128, 517) (20, 1)\n"
     ]
    }
   ],
   "source": [
    "### Saving smaller sample for testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "# Define file and species\n",
    "species1 = 'amecro'\n",
    "species2 = 'whcspa'\n",
    "samples_per_class = 30  # Smaller sample for testing\n",
    "\n",
    "# Extract and transpose a limited number of samples\n",
    "X1 = np.transpose(f[species1][:, :, :samples_per_class], (2, 0, 1))  # (30, 128, 517)\n",
    "X2 = np.transpose(f[species2][:, :, :samples_per_class], (2, 0, 1))  # (30, 128, 517)\n",
    "\n",
    "# Create feature and label arrays\n",
    "X = np.concatenate((X1, X2), axis=0)  # Shape: (60, 128, 517)\n",
    "y = np.concatenate((np.ones(X1.shape[0]), np.zeros(X2.shape[0])))  # Shape: (60,)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=13)\n",
    "\n",
    "# Convert labels to binary class format\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)\n",
    "\n",
    "# Check final shapes\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87957c8e-b1b1-4ca9-952b-a2213e2d7c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nnaga\\miniconda3\\envs\\myenvname\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 379ms/step - accuracy: 0.4167 - loss: 335.8305 - val_accuracy: 0.5000 - val_loss: 313.2868\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.5625 - loss: 183.6291 - val_accuracy: 0.5000 - val_loss: 25.5856\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.4375 - loss: 73.0363 - val_accuracy: 0.5000 - val_loss: 74.2484\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.5000 - loss: 68.9358 - val_accuracy: 0.5000 - val_loss: 4.0409\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.5625 - loss: 9.2363 - val_accuracy: 0.5000 - val_loss: 21.6716\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.5208 - loss: 10.4941 - val_accuracy: 0.7500 - val_loss: 0.5568\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.8125 - loss: 1.0439 - val_accuracy: 0.6250 - val_loss: 0.4777\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.8958 - loss: 0.2758 - val_accuracy: 0.5000 - val_loss: 0.5787\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 1.0000 - loss: 0.1786 - val_accuracy: 0.6250 - val_loss: 0.6733\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.8333 - loss: 1.0608 - val_accuracy: 0.5000 - val_loss: 2.5085\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.6042 - loss: 2.9496 - val_accuracy: 0.5000 - val_loss: 0.7822\n",
      "Test Accuracy: 90.00%\n"
     ]
    }
   ],
   "source": [
    "### Optimal Model -------------------------------------------------------------------------\n",
    "### Define Nerual Network Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    # detects patterns in images\n",
    "        # 32 filters, 3x3 kernel, ReLU activation, input shape (height, width, channel)\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 517, 1)),\n",
    "    # reduce dimensionality\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # more complex features (increase to 64 filters)\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # converts multi dimensional space to 1D vector\n",
    "    Flatten(),\n",
    "    # hidden layer\n",
    "    Dense(64, activation='relu'),\n",
    "    # dropout later 50% nodes randomly dropped\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary output\n",
    "])\n",
    "\n",
    "### Compile Neural Network Model\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "### Train Neural Network Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# evaluate model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51cecab5-ba81-495d-abea-b96543825aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 464ms/step - accuracy: 0.5833 - loss: 160.3083 - val_accuracy: 0.5000 - val_loss: 131.2066\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 297ms/step - accuracy: 0.5000 - loss: 87.1581 - val_accuracy: 0.5000 - val_loss: 0.6816\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 301ms/step - accuracy: 0.4375 - loss: 0.9514 - val_accuracy: 0.5000 - val_loss: 0.6855\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - accuracy: 0.4792 - loss: 1.8176 - val_accuracy: 0.5000 - val_loss: 0.6758\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 357ms/step - accuracy: 0.5000 - loss: 0.8350 - val_accuracy: 0.3750 - val_loss: 0.6934\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323ms/step - accuracy: 0.5000 - loss: 0.6933 - val_accuracy: 0.3750 - val_loss: 0.6934\n",
      "Test Accuracy: 45.00%\n"
     ]
    }
   ],
   "source": [
    "### Higher Convolutional Layers -------------------------------------------------------------------------\n",
    "### Define Nerual Network Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    # detects patterns in images\n",
    "        # 32 filters, 3x3 kernel, ReLU activation, input shape (height, width, channel)\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 517, 1)),\n",
    "    # reduce dimensionality\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # more complex features (increase to 64 filters)\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # more complex features (increase to 128 filters)\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "\n",
    "    # converts multi dimensional space to 1D vector\n",
    "    Flatten(),\n",
    "    # hidden layer\n",
    "    Dense(64, activation='relu'),\n",
    "    # dropout later 50% nodes randomly dropped\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary output\n",
    "])\n",
    "\n",
    "### Compile Neural Network Model\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "### Train Neural Network Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# evaluate model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9adfd56-32aa-443b-bcd5-a9ee4027b984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step - accuracy: 0.3958 - loss: 598.5447 - val_accuracy: 0.5000 - val_loss: 51.2918\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.5625 - loss: 69.2561 - val_accuracy: 0.5000 - val_loss: 195.4090\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.4167 - loss: 143.7131 - val_accuracy: 0.5000 - val_loss: 51.2604\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271ms/step - accuracy: 0.5625 - loss: 69.2797 - val_accuracy: 0.5000 - val_loss: 16.9202\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.5000 - loss: 16.6135 - val_accuracy: 0.6250 - val_loss: 0.6054\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.3958 - loss: 69.5148 - val_accuracy: 0.5000 - val_loss: 1.6665\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.4792 - loss: 1.7231 - val_accuracy: 0.5000 - val_loss: 0.6922\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.5417 - loss: 19.3491 - val_accuracy: 0.5000 - val_loss: 0.7812\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 215ms/step - accuracy: 0.4583 - loss: 15.4222 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.5208 - loss: 0.6820 - val_accuracy: 0.5000 - val_loss: 0.8493\n",
      "Test Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "### Smaller Kernel -------------------------------------------------------------------------\n",
    "### Define Nerual Network Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    # detects patterns in images\n",
    "        # 32 filters, 2x2 kernel, ReLU activation, input shape (height, width, channel)\n",
    "    Conv2D(32, (2, 2), activation='relu', input_shape=(128, 517, 1)),\n",
    "    # reduce dimensionality\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # more complex features (increase to 64 filters)\n",
    "    Conv2D(64, (2, 2), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # converts multi dimensional space to 1D vector\n",
    "    Flatten(),\n",
    "    # hidden layer\n",
    "    Dense(64, activation='relu'),\n",
    "    # dropout later 50% nodes randomly dropped\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary output\n",
    "])\n",
    "\n",
    "### Compile Neural Network Model\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "### Train Neural Network Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# evaluate model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f4d668-b930-42ec-941c-892fbf0678ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530ms/step - accuracy: 0.4792 - loss: 330.6016 - val_accuracy: 0.5000 - val_loss: 595.0089\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318ms/step - accuracy: 0.5208 - loss: 292.6227 - val_accuracy: 0.5000 - val_loss: 66.2463\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312ms/step - accuracy: 0.5625 - loss: 29.6536 - val_accuracy: 0.5000 - val_loss: 19.1794\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 323ms/step - accuracy: 0.4375 - loss: 13.4317 - val_accuracy: 0.5000 - val_loss: 25.8764\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - accuracy: 0.5208 - loss: 14.4486 - val_accuracy: 0.5000 - val_loss: 7.1211\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343ms/step - accuracy: 0.5000 - loss: 5.8783 - val_accuracy: 0.5000 - val_loss: 6.2183\n",
      "Test Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "### Reduce Dropout -------------------------------------------------------------------------\n",
    "### Define Nerual Network Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    # detects patterns in images\n",
    "        # 32 filters, 3x3 kernel, ReLU activation, input shape (height, width, channel)\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 517, 1)),\n",
    "    # reduce dimensionality\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # more complex features (increase to 64 filters)\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # more complex features (increase to 128 filters)\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "\n",
    "    # converts multi dimensional space to 1D vector\n",
    "    Flatten(),\n",
    "    # hidden layer\n",
    "    Dense(128, activation='relu'),\n",
    "    # dropout later 50% nodes randomly dropped\n",
    "    Dropout(0.4),\n",
    "    Dense(1, activation='sigmoid')  # Binary output\n",
    "])\n",
    "\n",
    "### Compile Neural Network Model\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "### Train Neural Network Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# evaluate model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24737ec8-15a1-45a6-adef-c75444742e17",
   "metadata": {},
   "source": [
    "### Multi- Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d15a6deb-4e51-4319-9737-9e0fb6fb5135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amecro: original shape (128, 517, 66)\n",
      "amerob: original shape (128, 517, 172)\n",
      "bewwre: original shape (128, 517, 144)\n",
      "bkcchi: original shape (128, 517, 45)\n",
      "daejun: original shape (128, 517, 125)\n",
      "houfin: original shape (128, 517, 84)\n",
      "houspa: original shape (128, 517, 630)\n",
      "norfli: original shape (128, 517, 37)\n",
      "rewbla: original shape (128, 517, 187)\n",
      "sonspa: original shape (128, 517, 263)\n",
      "spotow: original shape (128, 517, 137)\n",
      "whcspa: original shape (128, 517, 91)\n",
      "(241, 128, 517) (241, 12)\n",
      "(119, 128, 517) (119, 12)\n"
     ]
    }
   ],
   "source": [
    "### Saving smaller sample for testing\n",
    "import numpy as np\n",
    "\n",
    "# Define all species\n",
    "species_list = ['amecro', 'amerob', 'bewwre', 'bkcchi', 'daejun', 'houfin', \n",
    "                'houspa', 'norfli', 'rewbla', 'sonspa', 'spotow', 'whcspa']\n",
    "\n",
    "# Sample size per class\n",
    "samples_per_class = 30  # Adjust as needed\n",
    "\n",
    "# Initialize lists\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Loop through species to collect limited data\n",
    "for i, species in enumerate(species_list):\n",
    "    dset = f[species]\n",
    "    print(f\"{species}: original shape {dset.shape}\")\n",
    "\n",
    "    available_samples = dset.shape[2]\n",
    "    use_samples = min(samples_per_class, available_samples)\n",
    "\n",
    "    X_species = np.transpose(dset[:, :, :use_samples], (2, 0, 1))\n",
    "    X.append(X_species)\n",
    "    y.append(np.full(use_samples, i))\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.concatenate(X, axis=0)\n",
    "y = np.concatenate(y, axis=0)\n",
    "\n",
    "### Split into Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=13)\n",
    "\n",
    "# Convert target variable to binary class\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)\n",
    "\n",
    "# Check final shapes\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b4ff1a5-9e3c-4e4b-b212-09705ac580d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 304ms/step - accuracy: 0.1419 - loss: 65.6166 - val_accuracy: 0.1020 - val_loss: 2.4966\n",
      "Epoch 2/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 300ms/step - accuracy: 0.0667 - loss: 2.6316 - val_accuracy: 0.0816 - val_loss: 2.4869\n",
      "Epoch 3/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 301ms/step - accuracy: 0.1519 - loss: 2.4746 - val_accuracy: 0.1429 - val_loss: 2.4646\n",
      "Epoch 4/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 362ms/step - accuracy: 0.2845 - loss: 2.3718 - val_accuracy: 0.2449 - val_loss: 2.2908\n",
      "Epoch 5/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 376ms/step - accuracy: 0.3193 - loss: 2.1052 - val_accuracy: 0.2857 - val_loss: 2.2665\n",
      "Epoch 6/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 392ms/step - accuracy: 0.4516 - loss: 1.8130 - val_accuracy: 0.2449 - val_loss: 2.7733\n",
      "Epoch 7/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 401ms/step - accuracy: 0.5970 - loss: 1.3980 - val_accuracy: 0.2041 - val_loss: 2.3016\n",
      "Epoch 8/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 374ms/step - accuracy: 0.7395 - loss: 1.0790 - val_accuracy: 0.1837 - val_loss: 2.3790\n",
      "Epoch 9/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 385ms/step - accuracy: 0.8066 - loss: 0.9788 - val_accuracy: 0.1633 - val_loss: 4.4374\n",
      "Epoch 10/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 423ms/step - accuracy: 0.9123 - loss: 0.3271 - val_accuracy: 0.1837 - val_loss: 3.4445\n",
      "Test Accuracy: 30.25%\n"
     ]
    }
   ],
   "source": [
    "### Optimal Model ---------------------------------------------------------------------\n",
    "### Define Multi-Class Neural Netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 517, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(12, activation='softmax')  # Output layer for multi class\n",
    "])\n",
    "\n",
    "### Compile Multi-Class Neural Netowrk\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Multi-class loss function\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "### Train Multi-Class Neural Network\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=16,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# evaluate model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f55a887b-b4bd-4718-8172-7abc69748d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nnaga\\miniconda3\\envs\\myenvname\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 223ms/step - accuracy: 0.0902 - loss: 513.6301 - val_accuracy: 0.1020 - val_loss: 2.4829\n",
      "Epoch 2/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - accuracy: 0.1067 - loss: 2.5840 - val_accuracy: 0.1633 - val_loss: 2.4817\n",
      "Epoch 3/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 250ms/step - accuracy: 0.1273 - loss: 2.4701 - val_accuracy: 0.0816 - val_loss: 2.4912\n",
      "Epoch 4/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 249ms/step - accuracy: 0.2355 - loss: 2.3956 - val_accuracy: 0.1429 - val_loss: 2.5280\n",
      "Epoch 5/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 241ms/step - accuracy: 0.3124 - loss: 2.1883 - val_accuracy: 0.1020 - val_loss: 2.4352\n",
      "Epoch 6/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 234ms/step - accuracy: 0.5588 - loss: 1.7150 - val_accuracy: 0.1429 - val_loss: 2.5019\n",
      "Epoch 7/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 233ms/step - accuracy: 0.6456 - loss: 1.1749 - val_accuracy: 0.1837 - val_loss: 2.9178\n",
      "Epoch 8/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 271ms/step - accuracy: 0.7916 - loss: 0.7197 - val_accuracy: 0.1837 - val_loss: 3.5997\n",
      "Epoch 9/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 262ms/step - accuracy: 0.8753 - loss: 0.5325 - val_accuracy: 0.1837 - val_loss: 3.8006\n",
      "Epoch 10/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 247ms/step - accuracy: 0.8956 - loss: 0.4552 - val_accuracy: 0.2449 - val_loss: 4.1292\n",
      "Epoch 11/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 238ms/step - accuracy: 0.9583 - loss: 0.2098 - val_accuracy: 0.2245 - val_loss: 4.2369\n",
      "Epoch 12/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 253ms/step - accuracy: 0.8925 - loss: 0.3483 - val_accuracy: 0.1429 - val_loss: 3.9198\n",
      "Epoch 13/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 280ms/step - accuracy: 0.9401 - loss: 0.2443 - val_accuracy: 0.2041 - val_loss: 4.1639\n",
      "Epoch 14/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 281ms/step - accuracy: 0.8630 - loss: 0.3867 - val_accuracy: 0.1837 - val_loss: 4.4689\n",
      "Epoch 15/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 299ms/step - accuracy: 0.9158 - loss: 0.2770 - val_accuracy: 0.2041 - val_loss: 5.6473\n",
      "Test Accuracy: 31.09%\n"
     ]
    }
   ],
   "source": [
    "### Higher dropout ---------------------------------------------------------------------\n",
    "### Define Multi-Class Neural Netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 517, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(12, activation='softmax')  # Output layer for multi class\n",
    "])\n",
    "\n",
    "### Compile Multi-Class Neural Netowrk\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Multi-class loss function\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "### Train Multi-Class Neural Network\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=16,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# evaluate model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee7fd443-bb4d-4155-ba71-cd25ab89cd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 377ms/step - accuracy: 0.1026 - loss: 48.2686 - val_accuracy: 0.1020 - val_loss: 2.9885\n",
      "Epoch 2/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 408ms/step - accuracy: 0.0798 - loss: 3.0825 - val_accuracy: 0.1020 - val_loss: 2.4855\n",
      "Epoch 3/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 392ms/step - accuracy: 0.0654 - loss: 2.5116 - val_accuracy: 0.0816 - val_loss: 2.4861\n",
      "Epoch 4/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 386ms/step - accuracy: 0.1088 - loss: 2.4851 - val_accuracy: 0.1224 - val_loss: 2.4863\n",
      "Epoch 5/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 392ms/step - accuracy: 0.0608 - loss: 2.4843 - val_accuracy: 0.0000e+00 - val_loss: 2.4866\n",
      "Epoch 6/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 387ms/step - accuracy: 0.1434 - loss: 2.4822 - val_accuracy: 0.1020 - val_loss: 2.4790\n",
      "Epoch 7/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 393ms/step - accuracy: 0.1568 - loss: 2.4773 - val_accuracy: 0.0204 - val_loss: 2.4872\n",
      "Epoch 8/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 369ms/step - accuracy: 0.1464 - loss: 2.4833 - val_accuracy: 0.0000e+00 - val_loss: 2.4880\n",
      "Epoch 9/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 368ms/step - accuracy: 0.1259 - loss: 2.4818 - val_accuracy: 0.0204 - val_loss: 2.4816\n",
      "Test Accuracy: 11.76%\n"
     ]
    }
   ],
   "source": [
    "### More Convolutional Layers ---------------------------------------------------------------------\n",
    "### Define Multi-Class Neural Netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 517, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(12, activation='softmax')  # Output layer for multi class\n",
    "])\n",
    "\n",
    "### Compile Multi-Class Neural Netowrk\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Multi-class loss function\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "### Train Multi-Class Neural Network\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=16,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# evaluate model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "092dd8e4-266b-4352-9e5a-f8fb7370c133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 399ms/step - accuracy: 0.0755 - loss: 59.2262 - val_accuracy: 0.1020 - val_loss: 2.6901\n",
      "Epoch 2/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 403ms/step - accuracy: 0.1048 - loss: 2.7127 - val_accuracy: 0.1633 - val_loss: 2.5380\n",
      "Epoch 3/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 422ms/step - accuracy: 0.1107 - loss: 2.5019 - val_accuracy: 0.0408 - val_loss: 2.4877\n",
      "Epoch 4/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 428ms/step - accuracy: 0.1053 - loss: 2.4865 - val_accuracy: 0.1429 - val_loss: 2.4917\n",
      "Epoch 5/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 444ms/step - accuracy: 0.2108 - loss: 2.4970 - val_accuracy: 0.0408 - val_loss: 2.5640\n",
      "Epoch 6/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 424ms/step - accuracy: 0.1379 - loss: 2.4686 - val_accuracy: 0.0408 - val_loss: 2.5819\n",
      "Epoch 7/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 423ms/step - accuracy: 0.1664 - loss: 2.4751 - val_accuracy: 0.0612 - val_loss: 2.5421\n",
      "Test Accuracy: 19.33%\n"
     ]
    }
   ],
   "source": [
    "### Reduced Dropout ---------------------------------------------------------------------\n",
    "### Define Multi-Class Neural Netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 517, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(12, activation='softmax')  # Output layer for multi class\n",
    "])\n",
    "\n",
    "### Compile Multi-Class Neural Netowrk\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Multi-class loss function\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "### Train Multi-Class Neural Network\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=16,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# evaluate model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be4f6768-7d1a-42fb-90bc-9e75b9da8579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 208ms/step - accuracy: 0.0994 - loss: 278.4198 - val_accuracy: 0.0816 - val_loss: 2.5720\n",
      "Epoch 2/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 194ms/step - accuracy: 0.1427 - loss: 2.4679 - val_accuracy: 0.1224 - val_loss: 2.4255\n",
      "Epoch 3/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 222ms/step - accuracy: 0.4252 - loss: 2.1908 - val_accuracy: 0.1429 - val_loss: 2.4830\n",
      "Epoch 4/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 209ms/step - accuracy: 0.5930 - loss: 1.6130 - val_accuracy: 0.2041 - val_loss: 2.4605\n",
      "Epoch 5/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 217ms/step - accuracy: 0.8235 - loss: 0.8060 - val_accuracy: 0.1429 - val_loss: 2.7312\n",
      "Epoch 6/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - accuracy: 0.9050 - loss: 0.4969 - val_accuracy: 0.2041 - val_loss: 3.0407\n",
      "Epoch 7/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 236ms/step - accuracy: 0.9555 - loss: 0.2292 - val_accuracy: 0.2653 - val_loss: 3.5737\n",
      "Epoch 8/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 262ms/step - accuracy: 0.9583 - loss: 0.0900 - val_accuracy: 0.2245 - val_loss: 3.6687\n",
      "Epoch 9/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 268ms/step - accuracy: 0.9739 - loss: 0.0725 - val_accuracy: 0.2449 - val_loss: 3.6908\n",
      "Epoch 10/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 246ms/step - accuracy: 0.9952 - loss: 0.0558 - val_accuracy: 0.2653 - val_loss: 4.1844\n",
      "Epoch 11/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 237ms/step - accuracy: 0.9851 - loss: 0.0564 - val_accuracy: 0.2449 - val_loss: 4.3477\n",
      "Epoch 12/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 245ms/step - accuracy: 0.9800 - loss: 0.0578 - val_accuracy: 0.2449 - val_loss: 3.8445\n",
      "Test Accuracy: 26.05%\n"
     ]
    }
   ],
   "source": [
    "### Reduced Dropout, Less layers---------------------------------------------------------------------\n",
    "### Define Multi-Class Neural Netowrk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 517, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(12, activation='softmax')  # Output layer for multi class\n",
    "])\n",
    "\n",
    "### Compile Multi-Class Neural Netowrk\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Multi-class loss function\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "### Train Multi-Class Neural Network\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=16,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# evaluate model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(score[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
